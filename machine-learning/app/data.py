# -*- coding: utf-8 -*-

"""Support Vector Machine Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JSFgjIkvCRiQLhXD9wtEnBlnvdQaIPVb
"""

# 1. Importing Libraries


# Standard library
import re

# Third-party libraries
import numpy as np
import pandas as pd
import seaborn as sns
import gc
import matplotlib.pyplot as plt
import json

"""# 2. Reading Data

"""

# Mapping pesan error ke label pendek
ERROR_LABEL_MAP = {
    "Error: read ECONNRESET": "Koneksi Diputus",
    "Error: connect ECONNREFUSED 202.90.199.208:80": "Gagal Terhubung",
    "Error: connect ECONNRESET 202.90.199.208:80": "Koneksi Ditolak",
    "Error: connect ECONNREFUSED 127.0.0.1": "Gagal Koneksi Port Lokal",
    "Error: connect ECONNREFUSED 127.0.0.1:502": "Port Tidak Aktif",
    "Kuota habis": "Kuota Habis",
    "Error: connect ETIMEDOUT 202.90.199.208:80": "Timeout Server",
    "Error: socket hang up": "Koneksi Mendadak Terputus",
    "Error: Unexpected close tag": "Format Data Tidak Valid",
    "Error: read ETIMEDOUT": "Waktu Tunggu Koneksi Habis",
    "Network not available": "Jaringan Tidak Tersedia"
}

#Load Dataset
gc.enable()
data_directory_path = 'csv/'

# Membaca dataset
df = pd.read_csv(data_directory_path + 'error_device.csv')

def load_dataset():
    # Info umum
    baris_kolom = {
        "jumlah_baris": df.shape[0],
        "jumlah_kolom": df.shape[1]
    }

    tipe_data = df.dtypes.astype(str).to_dict()
    missing_values = df.isnull().sum().to_dict()
    duplicate_count = int(df.duplicated().sum())
    deskripsi = df.describe().to_dict()
    sample_data = df.head().to_dict(orient='records')

    result = {
        "sample_data": sample_data,
        "baris_dan_kolom": baris_kolom,
        "tipe_data": tipe_data,
        "missing_values": missing_values,
        "duplikat": duplicate_count,
        "deskriptif": deskripsi
    }

    return result

"""# 3. Data Cleaning

"""

def classify_error(message):
    """
    Mengklasifikasikan Error Message menjadi status:
    0 = Low, 1 = Warning, 2 = Critical
    """
    if pd.isna(message):
        return 1

    message = str(message).lower()

    if "kuota habis" in message or "quota" in message:
        return 0
    elif "etimedout" in message or "timeout" in message or "unreachable" in message or "low battery" in message:
        return 1
    elif "econnrefused" in message or "econnreset" in message or "disconnected" in message or "no data" in message:
        return 2
    else:
        return 1

def classify_message_type(message):
    """
    Memberikan kategori jenis error berdasarkan keyword.
    """
    message = str(message).lower()
    if "econnreset" in message or "econnrefused" in message:
        return 1  # Connection error
    elif "etimedout" in message or "timeout" in message:
        return 2  # Timeout
    elif "unreachable" in message or "unavailable" in message:
        return 3  # Network error
    elif "kuota" in message:
        return 4  # Kuota
    else:
        return 0  # Other

def extract_error_code(message):
    """
    Menangkap angka 3 atau 4 digit dari pesan error, jika ada.
    """
    if not isinstance(message, str):
        return 0
    match = re.search(r'\b\d{3,4}\b', message)
    return int(match.group()) if match else 0

def get_cleaned_df(save_cleaned=False, output_path="csv/error_device_cleaned.csv"):
    df_cleaned = df.drop_duplicates()
    df_cleaned = df_cleaned[df_cleaned["Timestamp"] != "#VALUE!"]
    df_cleaned["Timestamp"] = pd.to_datetime(df_cleaned["Timestamp"], errors="coerce")
    df_cleaned = df_cleaned.dropna(subset=["Timestamp"])

    # Tambahkan fitur
    df_cleaned["Status"] = df_cleaned["Error Message"].apply(classify_error)
    df_cleaned["Message Type"] = df_cleaned["Error Message"].apply(classify_message_type)
    df_cleaned["Error Code"] = df_cleaned["Error Message"].apply(extract_error_code)
    df_cleaned["Hour"] = df_cleaned["Timestamp"].dt.hour
    df_cleaned["Day"] = df_cleaned["Timestamp"].dt.day
    df_cleaned["Month"] = df_cleaned["Timestamp"].dt.month
    df_cleaned["Year"] = df_cleaned["Timestamp"].dt.year
    df_cleaned["Frequency"] = df_cleaned.groupby("Hour")["Error Message"].transform("count")
    df_cleaned["Simplified Message"] = df_cleaned["Error Message"].map(ERROR_LABEL_MAP).fillna("Lainnya")

    # Opsional: simpan ke CSV
    if save_cleaned:
        df_cleaned.to_csv(output_path, index=False)

    return df_cleaned

def clean_dataset():
    try:
        df_cleaned = get_cleaned_df()
        summary = {
            "total_data_awal": df.shape[0],
            "total_data_setelah_cleaning": df_cleaned.shape[0],
            "missing_values": df_cleaned.isnull().sum().to_dict(),
            "distribusi_status": df_cleaned['Status'].value_counts().to_dict(),
            "contoh_data": df_cleaned.head(1).to_dict(orient='records')
        }
        return summary
    except Exception as e:
        return {"error": str(e)}

"""# 4. Exploratory Data Analysis (EDA)"""

def hourly_error_trend():
    try:
        df_cleaned = get_cleaned_df()
        df_cleaned["Hour"] = df_cleaned["Timestamp"].dt.hour
        error_by_hour = df_cleaned['Hour'].value_counts().sort_index()
        return error_by_hour.to_dict()
    except Exception as e:
        return {"error": str(e)}

def top_hourly_error_messages(top_n=5):
    try:
        df_cleaned = get_cleaned_df()
        df_cleaned["Hour"] = df_cleaned["Timestamp"].dt.hour

        top_errors_per_hour = (
            df_cleaned.groupby(["Hour", "Simplified Message"])
            .size()
            .reset_index(name="Count")
        )

        top_errors = (
            top_errors_per_hour
            .sort_values(['Hour', 'Count'], ascending=[True, False])
            .groupby('Hour')
            .head(top_n)
        )

        return top_errors.to_dict(orient='records')
    except Exception as e:
        return {"error": str(e)}
    
def daily_status_trend():
    try:
        df_cleaned = get_cleaned_df()
        df_cleaned["Date"] = df_cleaned["Timestamp"].dt.date
        status_labels = {0: 'Low', 1: 'Warning', 2: 'Critical'}

        daily_status_counts = (
            df_cleaned.groupby(["Date", "Status"])
            .size()
            .reset_index(name="Count")
        )

        last_7_days = sorted(df_cleaned["Date"].unique())[-7:]
        filtered = daily_status_counts[daily_status_counts["Date"].isin(last_7_days)]
        filtered["Status Label"] = filtered["Status"].map(status_labels)

        result = (
            filtered.groupby(["Date", "Status Label"])["Count"]
            .sum()
            .unstack(fill_value=0)
            .reset_index()
            .to_dict(orient='records')
        )

        return result
    except Exception as e:
        return {"error": str(e)}


def top_daily_error_messages(top_n=3):
    try:
        df_cleaned = get_cleaned_df()
        df_cleaned["Date"] = df_cleaned["Timestamp"].dt.date

        daily_error_counts = (
            df_cleaned.groupby(["Date", "Simplified Message"])
            .size()
            .reset_index(name="Count")
        )

        last_7_days = sorted(df_cleaned["Date"].unique())[-7:]
        filtered = daily_error_counts[daily_error_counts["Date"].isin(last_7_days)]

        top_daily_errors = (
            filtered.sort_values(["Date", "Count"], ascending=[True, False])
            .groupby("Date")
            .head(top_n)
        )

        return top_daily_errors.to_dict(orient='records')
    except Exception as e:
        return {"error": str(e)}

def weekly_status_trend():
    try:
        df_cleaned = get_cleaned_df()
        df_cleaned["Week"] = df_cleaned["Timestamp"].dt.to_period("W").apply(lambda r: r.start_time.date())
        status_labels = {0: 'Low', 1: 'Warning', 2: 'Critical'}

        weekly_status_counts = (
            df_cleaned.groupby(["Week", "Status"])
            .size()
            .reset_index(name="Count")
        )

        last_5_weeks = sorted(df_cleaned["Week"].unique())[-5:]
        filtered = weekly_status_counts[weekly_status_counts["Week"].isin(last_5_weeks)]
        filtered["Status Label"] = filtered["Status"].map(status_labels)

        result = (
            filtered.groupby(["Week", "Status Label"])["Count"]
            .sum()
            .unstack(fill_value=0)
            .reset_index()
            .to_dict(orient='records')
        )

        return result
    except Exception as e:
        return {"error": str(e)}


def top_weekly_error_messages(top_n=3):
    try:
        df_cleaned = get_cleaned_df()
        df_cleaned["Week"] = df_cleaned["Timestamp"].dt.to_period("W").apply(lambda r: r.start_time.date())

        weekly_error_counts = (
            df_cleaned.groupby(["Week", "Simplified Message"])
            .size()
            .reset_index(name="Count")
        )

        last_5_weeks = sorted(df_cleaned["Week"].unique())[-5:]
        filtered = weekly_error_counts[weekly_error_counts["Week"].isin(last_5_weeks)]

        top_weekly_errors = (
            filtered.sort_values(["Week", "Count"], ascending=[True, False])
            .groupby("Week")
            .head(top_n)
        )

        return top_weekly_errors.to_dict(orient='records')
    except Exception as e:
        return {"error": str(e)}

def monthly_status_trend():
    try:
        df_cleaned = get_cleaned_df()
        df_cleaned["Month"] = df_cleaned["Timestamp"].dt.to_period("M").astype(str)
        monthly_trend = (
            df_cleaned.groupby(["Month", "Status"])
            .size()
            .reset_index(name="Count")
        )
        status_labels = {0: "Low", 1: "Warning", 2: "Critical"}
        monthly_trend["Status Label"] = monthly_trend["Status"].map(status_labels)
        return monthly_trend.to_dict(orient='records')
    except Exception as e:
        return {"error": str(e)}

def top_monthly_error_messages(top_n=3):
    try:
        df_cleaned = get_cleaned_df()
        df_cleaned["Month"] = df_cleaned["Timestamp"].dt.to_period("M").astype(str)

        monthly_error_msg = (
            df_cleaned.groupby(["Month", "Simplified Message"])
            .size()
            .reset_index(name="Count")
        )

        top_monthly = (
            monthly_error_msg
            .sort_values(["Month", "Count"], ascending=[True, False])
            .groupby("Month")
            .head(top_n)
        )
        return top_monthly.to_dict(orient="records")
    except Exception as e:
        return {"error": str(e)}

def error_status_distribution():
    try:
        df_cleaned = get_cleaned_df()
        status_labels = {0: "Low", 1: "Warning", 2: "Critical"}
        df_cleaned['Status Label'] = df_cleaned['Status'].map(status_labels)
        distribution = df_cleaned['Status Label'].value_counts().to_dict()
        return distribution
    except Exception as e:
        return {"error": str(e)}

def top_error_messages_per_status(top_n=5):
    try:
        df_cleaned = get_cleaned_df()
        status_labels = {0: "Low", 1: "Warning", 2: "Critical"}
        df_cleaned['Status Label'] = df_cleaned['Status'].map(status_labels)

        top_errors_by_status = (
            df_cleaned.groupby(['Status Label', 'Simplified Message'])
            .size()
            .reset_index(name='Count')
            .sort_values(['Status Label', 'Count'], ascending=[True, False])
        )

        top_errors_filtered = (
            top_errors_by_status.groupby('Status Label')
            .head(top_n)
            .reset_index(drop=True)
        )

        return top_errors_filtered.to_dict(orient='records')
    except Exception as e:
        return {"error": str(e)}

"""# 4. Data Selection"""

def get_selected_df():
    df_cleaned = get_cleaned_df()

    # Pilih kolom yang akan digunakan sebagai fitur dan label
    df_selected = df_cleaned[[
        "Simplified Message", # fitur teks pendek (untuk TF-IDF)
        "Error Message",      # fitur teks → untuk TF-IDF
        "Message Type",       # fitur numerik kategori error
        "Error Code",         # fitur numerik (jika ada)
        "Frequency",          # fitur numerik (jumlah error per jam)
        "Hour", "Day", "Month", "Year",  # fitur waktu
        "Status"             # label klasifikasi
    ]].copy()

    return df_selected