# -*- coding: utf-8 -*-
"""Support Vector Machine Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JSFgjIkvCRiQLhXD9wtEnBlnvdQaIPVb

# 1. Importing Libraries
"""

# Standard library
import re
from collections import Counter

# Third-party libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction import text
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from imblearn.over_sampling import SMOTE

"""# 2. Reading Data

"""

#Load Google Drive and Dataset Path
from google.colab import drive
drive.mount('/content/drive')

error_device = "/content/drive/MyDrive/University/Semester-7/Model/error_device.csv"

# Membaca dataset
df = pd.read_csv(error_device)

# Menampilkan 5 baris pertama
print("5 Baris Pertama Data:")
display(df.head())

# Cek jumlah baris dan kolom
print(f"\nJumlah Baris: {df.shape[0]}, Jumlah Kolom: {df.shape[1]}")

# Cek tipe data setiap kolom
print("\nTipe Data Setiap Kolom:")
print(df.dtypes)

# Cek missing values
print("\nJumlah Missing Values per Kolom:")
print(df.isnull().sum())

# Cek data duplikat
duplicate_rows = df.duplicated().sum()
print(f"\nJumlah Data Duplikat: {duplicate_rows}")

# Statistik deskriptif untuk kolom numerik
print("\nStatistik Deskriptif:")
display(df.describe())

"""# 3. Data Cleaning

"""

# Hapus baris duplikat agar setiap data unik
df_cleaned = df.drop_duplicates()
print(f"Jumlah data setelah menghapus duplikasi: {df_cleaned.shape[0]}")

# Buang nilai Timestamp yang tidak valid dan konversi ke tipe datetime
df_cleaned = df_cleaned[df_cleaned["Timestamp"] != "#VALUE!"]
df_cleaned["Timestamp"] = pd.to_datetime(df_cleaned["Timestamp"], errors="coerce")
df_cleaned = df_cleaned.dropna(subset=["Timestamp"])

# Tampilkan jumlah nilai yang hilang di setiap kolom setelah pembersihan
print("\nJumlah nilai yang hilang setelah pembersihan:")
print(df_cleaned.isnull().sum())

# Tampilkan jumlah data setelah pembersihan
print(f"\nJumlah data setelah pembersihan: {df_cleaned.shape[0]}")

# Fungsi untuk mengklasifikasikan error berdasarkan pesan error
def classify_error(message):
    if pd.isna(message):
        return 0
    message = str(message)
    if "Kuota habis" in message:
        return 0
    elif "ETIMEDOUT" in message or "EHOSTUNREACH" in message:
        return 1
    elif "ECONNREFUSED" in message or "ECONNRESET" in message:
        return 2
    else:
        return 0

# Tambahkan kolom Status berdasarkan klasifikasi pesan error
df_cleaned['Status'] = df_cleaned['Error Message'].apply(classify_error)

# Tampilkan distribusi jumlah data tiap kelas Status
print("\nDistribusi Status:")
status_counts = df_cleaned['Status'].value_counts().sort_index()
for status, count in status_counts.items():
    print(f"Status {status}: {count} data")

# Tampilkan 5 data teratas setelah pembersihan
display(df_cleaned.head())

# Simpan data bersih ke file CSV (opsional)
# df_cleaned.to_csv("/content/drive/MyDrive/University/Semester-7/Model/error_device_cleaned.csv", index=False)

# Info dataset
print(df_cleaned.info())

# Statistik deskriptif untuk kolom numerik
print(df_cleaned.describe())

# Statistik deskriptif untuk kolom kategorikal
print(df_cleaned.describe(include=["object"]))

"""# 4. Exploratory Data Analysis (EDA)"""

# Ekstrak jam dari Timestamp dan hitung jumlah error per jam
df_cleaned["Hour"] = df_cleaned["Timestamp"].dt.hour
error_by_hour = df_cleaned['Hour'].value_counts().sort_index()

# Visualisasi tren error per jam
plt.figure(figsize=(12, 6))
plt.plot(error_by_hour.index, error_by_hour.values, marker='o', color='blue')
plt.xlabel("Jam")
plt.ylabel("Jumlah Error")
plt.title("Tren Error Berdasarkan Jam")
plt.xticks(range(0, 24))
plt.grid(True)
plt.show()

# Hitung jumlah error message per jam
top_errors_per_hour = (
    df_cleaned.groupby(["Hour", "Error Message"])
    .size()
    .reset_index(name="Count")
)

# Ambil top N error message terbanyak untuk tiap jam
top_n = 5
top_errors = (
    top_errors_per_hour
    .sort_values(['Hour', 'Count'], ascending=[True, False])
    .groupby('Hour')
    .head(top_n)
)

# Visualisasi barplot top error message per jam dengan warna berdasarkan pesan error
plt.figure(figsize=(16, 8))
sns.barplot(x="Hour", y="Count", hue="Error Message", data=top_errors, dodge=True, palette="Set2")

plt.title(f"Top {top_n} Error Message per Jam")
plt.xlabel("Jam")
plt.ylabel("Jumlah Error")
plt.legend(title="Error Message", bbox_to_anchor=(1.05, 1), loc="upper left")
plt.tight_layout()
plt.show()

# Buat kolom 'Date' dari Timestamp jika belum ada
df_cleaned["Date"] = df_cleaned["Timestamp"].dt.date

# Hitung jumlah Error Message per tanggal
daily_error_counts = (
    df_cleaned.groupby(["Date", "Error Message"])
    .size()
    .reset_index(name="Count")
)

# Ambil 7 hari terakhir dari data
last_7_days = sorted(df_cleaned["Date"].unique())[-7:]

# Filter data hanya untuk 7 hari terakhir
filtered_daily_errors = daily_error_counts[daily_error_counts["Date"].isin(last_7_days)]

# Ambil top N error message terbanyak untuk tiap hari
top_n = 3
top_daily_errors = (
    filtered_daily_errors
    .sort_values(['Date', 'Count'], ascending=[True, False])
    .groupby('Date')
    .head(top_n)
)

# Visualisasi barplot top error message per hari selama 7 hari terakhir
plt.figure(figsize=(16, 8))
sns.barplot(
    x="Date", y="Count", hue="Error Message",
    data=top_daily_errors, dodge=True, palette="Set3"
)

plt.title(f"Top {top_n} Error Message per Hari (7 Hari Terakhir)")
plt.xlabel("Tanggal")
plt.ylabel("Jumlah Error")
plt.xticks(rotation=45)
plt.legend(title="Error Message", bbox_to_anchor=(1.05, 1), loc="upper left")
plt.tight_layout()
plt.show()

# Hitung jumlah Status per tanggal
daily_status_counts = (
    df_cleaned.groupby(["Date", "Status"])
    .size()
    .reset_index(name="Count")
)

# Ambil 7 tanggal terakhir
last_7_days = sorted(df_cleaned["Date"].unique())[-7:]

# Filter hanya data dari 7 hari terakhir
filtered_daily_status = daily_status_counts[daily_status_counts["Date"].isin(last_7_days)]

# Mapping status ke label yang lebih informatif (opsional)
status_labels = {0: 'Low', 1: 'Warning', 2: 'Critical'}
filtered_daily_status["Status Label"] = filtered_daily_status["Status"].map(status_labels)

# Buat pivot table supaya tiap Status Label jadi kolom dan tanggal jadi index
pivot_status = filtered_daily_status.pivot(index="Date", columns="Status Label", values="Count").fillna(0)

# Plot tren jumlah Status per hari
plt.figure(figsize=(16, 8))
for status_label in pivot_status.columns:
    plt.plot(pivot_status.index, pivot_status[status_label], marker='o', label=status_label)

plt.title("Tren Jumlah Status Error per Hari (7 Hari Terakhir)")
plt.xlabel("Tanggal")
plt.ylabel("Jumlah Error")
plt.xticks(rotation=45)
plt.legend(title="Status")
plt.grid(True)
plt.tight_layout()
plt.show()

# Tambahkan kolom 'Week' berdasarkan nomor minggu dari Timestamp
df_cleaned["Week"] = df_cleaned["Timestamp"].dt.isocalendar().week

# Hitung jumlah error per minggu
weekly_errors = df_cleaned.groupby("Week").size()

# Visualisasi jumlah error per minggu dalam bentuk bar chart
plt.figure(figsize=(12, 6))
weekly_errors.plot(kind="bar", color="red")

plt.title("Jumlah Error per Minggu")
plt.xlabel("Minggu ke-")
plt.ylabel("Jumlah Error")
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# Hitung jumlah error per minggu per Status
weekly_status_counts = (
    df_cleaned.groupby(["Week", "Status"])
    .size()
    .reset_index(name="Count")
)

# Mapping status ke label yang informatif (opsional)
status_labels = {0: 'Low', 1: 'Warning', 2: 'Critical'}
weekly_status_counts["Status Label"] = weekly_status_counts["Status"].map(status_labels)

# Visualisasi tren jumlah error per Status tiap minggu
plt.figure(figsize=(12, 6))
sns.lineplot(x="Week", y="Count", hue="Status Label", data=weekly_status_counts, marker="o", palette="Set1")

plt.title("Tren Jumlah Status Error per Minggu")
plt.xlabel("Minggu")
plt.ylabel("Jumlah Error")
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

# Hitung jumlah error message per minggu
weekly_error_msg = (
    df_cleaned.groupby(["Week", "Error Message"])
    .size()
    .reset_index(name="Count")
)

# Ambil top 3 error message tiap minggu
top_n = 3
top_weekly_error_msg = (
    weekly_error_msg
    .sort_values(["Week", "Count"], ascending=[True, False])
    .groupby("Week")
    .head(top_n)
)

# Visualisasi barplot top error message per minggu
plt.figure(figsize=(16, 8))
sns.barplot(x="Week", y="Count", hue="Error Message", data=top_weekly_error_msg, dodge=True, palette="Set2")

plt.title(f"Top {top_n} Error Message per Minggu")
plt.xlabel("Minggu")
plt.ylabel("Jumlah Error")
plt.xticks(rotation=45)
plt.legend(title="Error Message", bbox_to_anchor=(1.05, 1), loc="upper left")
plt.tight_layout()
plt.show()

# Tambahkan kolom 'Month' berdasarkan bulan dari Timestamp
df_cleaned["Month"] = df_cleaned["Timestamp"].dt.to_period("M").astype(str)

# Visualisasi jumlah error per bulan
plt.figure(figsize=(12, 6))
sns.countplot(x=df_cleaned["Month"], order=sorted(df_cleaned["Month"].unique()), color="royalblue")

plt.xticks(rotation=45)
plt.xlabel("Bulan")
plt.ylabel("Jumlah Error")
plt.title("Distribusi Error per Bulan")
plt.show()

# Hitung jumlah status per bulan
monthly_status_trend = (
    df_cleaned.groupby(["Month", "Status"])
    .size()
    .reset_index(name="Count")
)

# Mapping status
status_labels = {0: "Low", 1: "Warning", 2: "Critical"}
monthly_status_trend["Status Label"] = monthly_status_trend["Status"].map(status_labels)

# Visualisasi tren status
plt.figure(figsize=(14, 7))
sns.lineplot(data=monthly_status_trend, x="Month", y="Count", hue="Status Label", marker="o")
plt.title("Tren Status Error per Bulan")
plt.xlabel("Bulan")
plt.ylabel("Jumlah Error")
plt.xticks(rotation=45)
plt.legend(title="Status", bbox_to_anchor=(1.05, 1), loc="upper left")
plt.tight_layout()
plt.grid(True)
plt.show()

# Hitung jumlah error message per bulan
monthly_error_msg = (
    df_cleaned.groupby(["Month", "Error Message"])
    .size()
    .reset_index(name="Count")
)

# Ambil top 3 error message tiap bulan
top_n = 3
top_monthly_error_msg = (
    monthly_error_msg
    .sort_values(["Month", "Count"], ascending=[True, False])
    .groupby("Month")
    .head(top_n)
)

# Visualisasi error message tiap bulan
plt.figure(figsize=(16, 8))
sns.barplot(x="Month", y="Count", hue="Error Message", data=top_monthly_error_msg, dodge=True, palette="Pastel2")
plt.title(f"Top {top_n} Error Message per Bulan")
plt.xlabel("Bulan")
plt.ylabel("Jumlah Error")
plt.xticks(rotation=45)
plt.legend(title="Error Message", bbox_to_anchor=(1.05, 1), loc="upper left")
plt.tight_layout()
plt.show()

# Ubah kode Status menjadi label teks yang mudah dibaca
status_labels = {0: "Low", 1: "Warning", 2: "Critical"}
df_cleaned['Status Label'] = df_cleaned['Status'].map(status_labels)

# Visualisasi distribusi Status Error dengan pie chart
plt.figure(figsize=(6, 6))
df_cleaned['Status Label'].value_counts().plot.pie(
    autopct='%1.1f%%',
    startangle=140,
    colors=["#90ee90", "#ffcc00", "#ff6666"]
)
plt.title("Distribusi Status Error")
plt.ylabel("")
plt.tight_layout()
plt.show()

# Hitung jumlah kemunculan tiap Error Message
error_counts = df_cleaned['Error Message'].value_counts()

# Ambil top 5 error
top_n = 5
top_errors = error_counts.head(top_n)

# Gabungkan sisa error sebagai 'Lainnya'
others = error_counts[top_n:].sum()
error_labels = list(top_errors.index) + ['Lainnya']
error_values = list(top_errors.values) + [others]

# Visualisai menggunakan Pie Chart
plt.figure(figsize=(7, 7))
plt.pie(
    error_values,
    labels=error_labels,
    autopct='%1.1f%%',
    startangle=140,
    colors=sns.color_palette("pastel")[0:top_n+1]
)

plt.title(f"Distribusi Top {top_n} Error Message")
plt.tight_layout()
plt.show()

# Pastikan label status sudah ada dalam bentuk teks
status_labels = {0: "Low", 1: "Warning", 2: "Critical"}
df_cleaned['Status Label'] = df_cleaned['Status'].map(status_labels)

# Hitung jumlah tiap Error Message per Status
top_n = 5
top_errors_by_status = (
    df_cleaned.groupby(['Status Label', 'Error Message'])
    .size()
    .reset_index(name='Count')
    .sort_values(['Status Label', 'Count'], ascending=[True, False])
)

# Ambil top 5 error message untuk setiap status
top_errors_filtered = (
    top_errors_by_status.groupby('Status Label')
    .head(top_n)
    .reset_index(drop=True)
)

# Visualisasi barplot top error message per status dengan warna sesuai status
plt.figure(figsize=(14, 8))
sns.barplot(
    data=top_errors_filtered,
    x='Count',
    y='Error Message',
    hue='Status Label',
    palette={'Low': '#90ee90', 'Warning': '#ffcc00', 'Critical': '#ff6666'}
)

plt.title(f"Top {top_n} Error Message per Status")
plt.xlabel("Jumlah Error")
plt.ylabel("Error Message")
plt.legend(title="Status", bbox_to_anchor=(1.05, 1), loc="upper left")
plt.tight_layout()
plt.show()

# Hitung jumlah kemunculan setiap error message
error_counts = df_cleaned["Error Message"].value_counts()

# Hitung jumlah error unik dan tidak unik
num_unique = (error_counts == 1).sum()
num_not_unique = (error_counts > 1).sum()

# Buat pie chart
plt.figure(figsize=(6, 6))
plt.pie([num_unique, num_not_unique], labels=["Unik (1x Muncul)", "Tidak Unik (>1x Muncul)"],
        autopct="%1.1f%%", colors=["royalblue", "tomato"], startangle=90)
plt.title("Distribusi Error Message Unik vs Tidak Unik")
plt.show()

"""# 4. Data Selection"""

# Pilih kolom yang dibutuhkan dari df_cleaned
df_selected = df_cleaned[["Timestamp", "Error Message"]].copy()

# Ekstrak informasi waktu dari kolom Timestamp
df_selected["Hour"] = df_selected["Timestamp"].dt.hour   # Jam
df_selected["Day"] = df_selected["Timestamp"].dt.day     # Tanggal
df_selected["Month"] = df_selected["Timestamp"].dt.month # Bulan
df_selected["Year"] = df_selected["Timestamp"].dt.year   # Tahun

"""# 5. Data Transformation"""

# Ubah teks Error Message menjadi fitur TF-IDF dengan maksimal 100 fitur
vectorizer = TfidfVectorizer(max_features=100)
X_tfidf = vectorizer.fit_transform(df_selected["Error Message"]).toarray()

# Buat DataFrame dari hasil TF-IDF
df_tfidf = pd.DataFrame(X_tfidf, columns=vectorizer.get_feature_names_out())

# Gabungkan fitur waktu dengan fitur TF-IDF
df_transformed = pd.concat([df_selected[["Hour", "Day", "Month", "Year"]].reset_index(drop=True),
                            df_tfidf.reset_index(drop=True)], axis=1)

# Tambahkan kolom label Status
df_transformed['Status'] = df_cleaned['Status'].values

# Optimasi tipe data untuk menghemat memori
float_cols = df_transformed.select_dtypes(include=["float64"]).columns
df_transformed[float_cols] = df_transformed[float_cols].astype("float32")

int_cols = df_transformed.select_dtypes(include=["int32", "int64"]).columns
df_transformed[int_cols] = df_transformed[int_cols].apply(pd.to_numeric, downcast="integer")

# Tampilkan info dataset dan 5 baris pertama
print(df_transformed.info())
display(df_transformed.head())

# # Simpan data hasil transformasi ke CSV (opsional)
# df_transformed.to_csv("/content/drive/MyDrive/University/Semester-7/Model/error_device_transformed.csv", index=False)

# Pisahkan fitur dan target
X = df_transformed.drop(columns=["Status"])
y = df_transformed["Status"]

# Lakukan PCA untuk reduksi dimensi ke 2 komponen
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# Buat DataFrame hasil PCA dengan label Status
df_pca = pd.DataFrame(X_pca, columns=["PC1", "PC2"])
df_pca["Status"] = y.values

# Visualisasi scatter plot hasil PCA
plt.figure(figsize=(8,6))
sns.scatterplot(data=df_pca, x="PC1", y="PC2", hue="Status", palette="Set1", alpha=0.7)
plt.title("Distribusi Titik Data setelah PCA (TF-IDF + Fitur Waktu)")
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.legend(title="Status", labels=["Low (0)", "Warning (1)", "Critical (2)"])
plt.grid(True)
plt.tight_layout()
plt.show()

"""# 7. Split Data"""

# Pisahkan fitur dan label
X = df_transformed.drop(columns=["Status"])
y = df_transformed["Status"]

# Bagi data menjadi training (70%) dan testing (30%) dengan stratifikasi label
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# Tampilkan jumlah data di masing-masing set
print("Jumlah data training:", X_train.shape[0])
print("Jumlah data testing:", X_test.shape[0])

"""# 8. Oversampling"""

# Cek distribusi label pada data training
label_counts = y_train.value_counts().sort_index()
print("Distribusi Label Status (y_train):")
print(label_counts)

# Visualisasi distribusi label sebelum SMOTE
plt.figure(figsize=(6, 4))
sns.barplot(x=label_counts.index, y=label_counts.values, palette="Set2")
plt.xticks([0, 1, 2], ["Low", "Warning", "Critical"])
plt.title("Distribusi Label Status sebelum SMOTE")
plt.xlabel("Label Status")
plt.ylabel("Jumlah")
plt.show()

# Inisialisasi SMOTE untuk oversampling
smote = SMOTE(random_state=42)

# Terapkan SMOTE pada data training untuk menyeimbangkan kelas
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

# Cek distribusi label setelah SMOTE
print("Distribusi Label Setelah SMOTE:", Counter(y_train_balanced))

# Visualisasi distribusi label setelah SMOTE
counter = Counter(y_train_balanced)
labels = ["Low", "Warning", "Critical"]
values = [counter[0], counter[1], counter[2]]

plt.figure(figsize=(6, 4))
sns.barplot(x=labels, y=values, palette="Set2")
plt.title("Distribusi Label Setelah SMOTE")
plt.xlabel("Label Status")
plt.ylabel("Jumlah Sampel")
plt.tight_layout()
plt.show()

# Inisialisasi dan terapkan SMOTE untuk menyeimbangkan data training
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

# Tampilkan distribusi label setelah SMOTE
print("Distribusi Label Setelah SMOTE:", Counter(y_train_balanced))